import os
import pandas as pd
import geemap as gm
import json
import seaborn as sns
import geopandas as gpd
import matplotlib.pyplot as plt
from datetime import datetime, timedelta


import ee
ee.Authenticate()
ee.Initialize(project='vics-testing-gee')





area_of_interest = ee.Geometry.Polygon(
        [[[107.05871643133393, -6.849336003871552],
          [107.05869497366182, -6.849730137563438],
          [107.05786885328523, -6.850486447249275],
          [107.05945672102204, -6.851445147944182],
          [107.06051887579194, -6.852350585719587],
          [107.06217111654512, -6.853117543431319],
          [107.06306160993806, -6.8538418912483445],
          [107.0646172911667, -6.854417107848376],
          [107.0651751906418, -6.853053630335792],
          [107.06629098959199, -6.853469065303514],
          [107.06673087187043, -6.852861890997824],
          [107.06569017477266, -6.852020367435975],
          [107.0631045252823, -6.851455800163294],
          [107.06188143797151, -6.850102966431695],
          [107.06084074087373, -6.8503160113684185],
          [107.05900610990754, -6.849804703360401]]])

# mengambil data citra satelit Sentinel-2 terhadap area of interest
imageCollection = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(area_of_interest)

start = '2022-01-01'
end = '2022-12-31'
imageCollectionBetweenDate = imageCollection.filterDate(start, end)

display(imageCollectionBetweenDate)


geojson_file = "extras/kecamatan_pandanwangi.geojson"
with open(geojson_file) as f:
    geojson = json.load(f) 

gee_fc = ee.FeatureCollection(geojson)

display(gee_fc.filter(ee.Filter.eq("KECAMATAN", "WARUNGKONDANG")).geometry())


possible_locations = gee_fc.geometry()


geojson_file = "extras/possible_locations_3.geojson"
with open(geojson_file) as f:
    geojson = json.load(f) 

gee_fc = ee.FeatureCollection(geojson)

lokasi_pandanwangi = gee_fc.geometry()


kampung_budaya_pandanwangi_area = ee.Geometry.Polygon(
        [[[107.05857425033932, -6.850107766807647],
          [107.05818801224117, -6.85055516106035],
          [107.05971150696163, -6.851492557181238],
          [107.05999045669918, -6.851886689090894],
          [107.06123500168209, -6.852525821224871],
          [107.0621898680914, -6.853015821947369],
          [107.06339149773007, -6.85393190890368],
          [107.0638850241888, -6.8540490826897],
          [107.06473260223751, -6.854549733996468],
          [107.06518321335201, -6.85465625548324],
          [107.06526904404049, -6.854496473244144],
          [107.06474333107357, -6.8541662564469314],
          [107.06503300964718, -6.8531756046827725],
          [107.06533341705685, -6.853026474131393],
          [107.0661166220892, -6.853527126512156],
          [107.06644921600704, -6.85319690904344],
          [107.06624536812191, -6.852749517269356],
          [107.0635417014349, -6.852025167792628],
          [107.06244736015682, -6.851023859351123],
          [107.06201820671444, -6.850203637039985],
          [107.06171779930477, -6.850139723553897],
          [107.06088095009213, -6.850320811742221],
          [107.05877809822445, -6.849607110836802]]])

kampung_budaya_pandanwangi = ee.Geometry.Point([107.066538, -6.8543419]);
tugu_pandanwangi = ee.Geometry.Point([-6.8446689,107.1199718])








def fetch_image_sentinel2(start, end, geometry=kampung_budaya_pandanwangi):
    collection = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \
        .filterBounds(geometry) \
        .filterDate(start, end) \
        .sort('system:time_start', True)
    
    collection_size = collection.size().getInfo()  
    if collection_size == 0:
        return None
    return collection
          # .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 50)) # Filter awan di bawah 10%

def fetch_image_ecmwf(start, end, geometry=kampung_budaya_pandanwangi_area):

    ecmwf_collection = (
        ee.ImageCollection('ECMWF/ERA5_LAND/DAILY_AGGR')
        .select([
            "temperature_2m",
            "temperature_2m_min",
            "temperature_2m_max",
            "total_precipitation_sum",
            "u_component_of_wind_10m",
            "v_component_of_wind_10m",
        ])
        .filterBounds(geometry)
        .filter(ee.Filter.date(start, end))
    )
    
    ecmwf_clipped = ecmwf_collection.map(lambda image: image.clip(geometry))
    
    def reduceImage(image):
        mean_dict = image.reduceRegion(
          reducer= ee.Reducer.mean(),
          geometry= geometry,
          scale= 100,
          maxPixels= 1e9
        )
        
        date = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd')
        feature_dict = mean_dict.combine({'date': date})
        
        return ee.Feature(None, feature_dict)
    
    features = ee.FeatureCollection(ecmwf_clipped.map(reduceImage))
    return features





def clip_image_collection(image_collection, geometry=kampung_budaya_pandanwangi_area):
    clipped_collection = image_collection.map(lambda image: 
        image.clip(geometry).copyProperties(image, image.propertyNames())
    )

    return clipped_collection

def calculate_mean(image):
    mean_dict = image.reduceRegion(
        reducer=ee.Reducer.mean(),
        scale=20,
        maxPixels=1e13
    )
    return image.set(mean_dict)

def preprocess_image_collection(image_collection):
    clipped = clip_image_collection(image_collection)
    clipped_with_means = clipped.map(calculate_mean)
    return clipped_with_means
        





def day_before(date):
    date_obj = datetime.strptime(date, "%Y%m%d")
    day_before = date_obj - timedelta(days=1)
    return day_before.strftime("%Y%m%d")

def day_after(date):
    date_obj = datetime.strptime(date, "%Y%m%d")
    day_after = date_obj + timedelta(days=1)
    return day_after.strftime("%Y%m%d")

def str_to_date(date_str):
    #example: 20240602 become 2024-06-02
    return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"

def find_date_range(start_date, end_date):
    path = "spatial_timeseries"
    csv_files = [f[:-4] for f in os.listdir(path) if f.endswith('.csv')]
    csv_files.sort()

    # print(csv_files)
    date_range_list = []
    curr = start_date

    for daterange in csv_files:
        start = daterange.split("to")[0]
        end = daterange.split("to")[1]

        if(start > curr):
            if start > end_date:
                # print("a")
                if curr != end_date:
                    date_range_list.append((curr, end_date))
                return date_range_list
            else:
                # print("b")
                date_range_list.append((curr, day_before(start)))

        curr = min(day_after(end), end_date)
        
    if(end_date > curr):
        # print("c")
        date_range_list.append((curr, end_date))
    
    return date_range_list

print(find_date_range("20220101", "20220105"))


def format_spatial_to_pandas(collection_with_means):
    size = collection_with_means.size()
    image_list = collection_with_means.toList(size)
    data = []
    start_date = ee.Date(ee.Image(image_list.get(0)).get('system:time_start')).format('YYYYMMdd').getInfo()
    end_date = ee.Date(ee.Image(image_list.get(size.subtract(1))).get('system:time_start')).format('YYYYMMdd').getInfo()
    
    print(f"Processing date: {str_to_date(start_date)} until {str_to_date(end_date)}")
    
    for i in range(image_list.size().getInfo()):
        image = ee.Image(image_list.get(i))
        
        image_id = image.get('system:id').getInfo()
        date = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()
        cloud_percent = image.get('CLOUDY_PIXEL_PERCENTAGE').getInfo()
    
        band_list = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B9', 'B11', 'B12']
        
        bands = {band: image.get(band).getInfo() for band in band_list}
        
        data.append({
            'date': ee.Date(date).format('YYYY-MM-dd').getInfo() if date else None,
            'cloud_percentage': cloud_percent,
            **bands
        })
        
        # Print for each image
        print(f'Date: {date}, Cloud: {cloud_percent}% done')

    df = pd.DataFrame(data)
    df.to_csv(f"spatial_timeseries/{start_date}to{end_date}.csv", index=False)

    return df


def process_by_date(start_date, end_date):
    range_to_process = find_date_range(start_date, end_date)
    print(range_to_process)
    for start, end in range_to_process:
        string_start = str_to_date(start)
        string_end = str_to_date(end)
        img_col = fetch_image_sentinel2(string_start, string_end)
        if img_col:
            preprocessed_img_col = preprocess_image_collection(img_col)
            print(f"Done fetching data,")
            format_spatial_to_pandas(preprocessed_img_col)
        else:
            print(f"Couldn't found image for date range {string_start} to {string_end}")
        

process_by_date("20220101", "20241201")

print("Congrats! All Done!")





def remove_outliers(df, feature):
    series = df[feature]
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1
    upper_fence = Q3 + 1.5 * IQR
    lower_fence = Q1 - 1.5 * IQR
    
    outliers = df[(df[feature] < lower_fence) | (df[feature] > upper_fence)]
    cleaned_outliers = df[(df[feature] >= lower_fence) & (df[feature] <= upper_fence)]
    return outliers, cleaned_outliers








def addNDVI(band4, band8):
    results = pd.Series([(a - b) / (a + b) for a, b in zip(band8, band4)])
    return results

def addEVI(band2, band4, band8):
    return 2.5 * ((band8/10000-band4/10000) / (band8/10000 + 6 * band4/10000 - 7.5 * band2/10000 + 1))

    
def load_df_all():
    dataframes = []
    path = "spatial_timeseries"
    csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]
    for file in csv_files:
        df = pd.read_csv(path + "/" + file)
        dataframes.append(df)

    merged_df = pd.concat(dataframes, ignore_index=True)
    merged_df['NDVI'] = addNDVI(merged_df['B4'], merged_df['B8'])
    merged_df['EVI'] = addEVI(merged_df['B2'], merged_df['B4'], merged_df['B8'])
    
    return merged_df


df = load_df_all()

try:
    df['date'] = pd.to_datetime(df['date'])
    
    # Set 'date' as the index
    df.set_index('date', inplace=True)
    df = df[~df.index.duplicated(keep='first')]
    df = df.asfreq('5D')
    df = df.sort_index()
    
    print(f"There are {df.isna().sum()['B1']} null rows, proceeding with ffill()")
    df = df.ffill()
except:
    ""
outliers, cleaned_df = remove_outliers(df, 'B1')


print(outliers.shape)
print(cleaned_df.shape)





def line_plot(df, start_date='1990-01-01', end_date='2050-01-01', features=['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B9', 'B11', 'B12']):
    df_long = df.reset_index().melt(id_vars='date', var_name='feature', value_name='value')
    df_long = df_long[df_long['feature'].isin(features)]
    filtered_by_date_df = df_long[(df_long['date'] >= start_date) & (df_long['date'] <= end_date)]
    
    
    sns.set(style="whitegrid")
    plt.figure(figsize=(12, 6))
    sns.lineplot(data=filtered_by_date_df, x='date', y='value', hue='feature')
    
    # Customization
    plt.title('Line Plot of Features Over Time')
    plt.xlabel('Date')
    plt.ylabel('Value')
    plt.xticks(rotation=45)
    plt.show()

def color_overtime(df, start_date='1990-01-01', end_date='2050-01-01'):
    range_df = df.loc[start_date:end_date]
    # normalized_df = (range_df - range_df.min()) / (range_df.max() - range_df.min())

    for idx, data in range_df.iterrows():
        r = data['B2'] / 10000
        g = data['B3'] / 10000
        b = data['B4'] / 10000

        fig, ax = plt.subplots(figsize=(2, 2))  # Adjust size if needed

        # Set the background color to the RGB value
        ax.set_facecolor((r, g, b))
        ax.set_xticks([])
        ax.set_title(idx)
        ax.set_yticks([])
        ax.set_xlim(0, 1)
        ax.set_ylim(0, 1)
        
        
        # Display the color
        plt.show()
    print(range_df.shape)

def print_date_cloud(df, start_date, end_date):
    range_df = df.loc[start_date:end_date]
    for idx, row in range_df.iterrows():
        print(f"Index: {idx}, Cloud Percentage: {row['cloud_percentage']}")

def df_to_excel(df):
    path = "debugging"
    df.to_excel(path + "/test.xlsx")
# color_overtime(cleaned_df, start_date="2022-01-01", end_date="2022-04-01")



# df_to_excel(df)


m = gm.Map(center=lokasi_pandanwangi.centroid().coordinates().getInfo()[::-1], zoom=13)

curr_kec = "WARUNGKONDANG"
lokasi = gee_fc.filter(ee.Filter.eq("KECAMATAN", curr_kec)).geometry()
# display(lokasi)
collection = (
    ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED")
    .filterBounds(lokasi_pandanwangi)
    .filter(ee.Filter.date("2022-01-01", "2023-02-01"))
    .map(lambda image: image.clip(lokasi_pandanwangi))
)


vis_params = {
    "bands": ['B4', 'B3', 'B2'],
    "min": 0.0,
    "max": 2500
}

def ndvi_formula(band_nir, band_red):
    return band_nir.subtract(band_red).divide(band_nir.add(band_red))

def add_ndvi(image):
    # mengambil nilai band NIR dan Red dari citra
    band_nir = image.select("B8")
    band_red = image.select("B5")
    
    # menghitung NDVI menggunakan fungsi ndvi_formula
    ndvi = ndvi_formula(band_nir, band_red).rename("NDVI")
    
    # menambahkan band NDVI ke citra
    return image.addBands(ndvi)

# def add_ndvi(image):
#     ndvi = image.normalizedDifference(["B8", "B5"]).rename("NDVI")
#     return image.addBands(ndvi)

collection_with_ndvi = collection.map(add_ndvi)

# membuat parameter untuk visualisasi, di mana nilai NDVI mendekati -1 akan direpresentasikan oleh merah, 0 oleh coklat, dan 1 oleh hijau

ndvi_vis = {
    "min": -1.0,
    "max": 1.0,
    "palette": ["red", "brown", "green"],
    "bands": "NDVI"
}

# print_date_cloud(df, "2022-12-01", "2024-12-01")
# m.add_time_slider(collection_with_ndvi, ndvi_vis, time_interval=5)
# m
m.add_time_slider(collection, vis_params, time_interval=4)
m


filename = "pixel_timeseries/percobaan_1.csv"

pixel_df = pd.read_csv(filename)


count_df = pixel_df.groupby('date').count()['latitude']


count_df.unique()



