import pandas as pd
import numpy as np
import sklearn
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from tslearn.metrics import dtw
from tslearn.utils import to_time_series
from sklearn.model_selection import cross_validate
from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import time


class MySawahClassification:
    def __init__(self, 
                 param_grid: Dict = None,
                 random_state: int = 42):
        self.param_grid = 


folder_name = 'sawah_classification/'

collected_data = ["campaka"]
evi = True
curr_kec = collected_data[0]
curr_kec = "evi_" + curr_kec if evi else curr_kec

#dtw_knn_2 -> datasetnya lebih besar
# https://code.earthengine.google.com/52607160b523092795f576172fb238b3

labeled_df = pd.read_csv(folder_name + "label_sawah_nonsawah_campaka.csv").drop([".geo", "system:index"], axis=1)
wilayah_df = pd.read_csv(folder_name + curr_kec + ".csv")
cluster_geo = wilayah_df[['cluster_id', '.geo']]
wilayah_df = wilayah_df.drop(".geo", axis=1)


wilayah_df.head()


columns = wilayah_df.columns.tolist()
renamed_columns = []

for col in columns:
    colname = ""
    if "T48MYT" in col:
        colname = col.split("_")[3][:8]
    elif "LC08" in col:
        colname = col.split("_")[5]
    elif "LE07" in col:
        colname = col.split("_")[3]
    renamed_columns.append(colname)

renamed_columns = renamed_columns[:-1]

old_new_col = dict(zip(columns, renamed_columns))


wilayah_df = wilayah_df.rename(columns=old_new_col)
# menghapus kolom yg namanya duplikat
wilayah_df = wilayah_df.loc[:, ~wilayah_df.columns.duplicated(keep='first')]

# mengurutkan kolom berdasarkan urutan tanggalnya
wilayah_df = wilayah_df.reindex(sorted(wilayah_df.columns), axis=1)

cluster_id = wilayah_df['cluster_id']
# print(cluster_id)
wilayah_df = wilayah_df.iloc[:, 1:-1].interpolate(axis=1)
wilayah_df = wilayah_df.bfill(axis=1)
wilayah_df = pd.concat([wilayah_df, cluster_id], axis=1)
print(wilayah_df)


wilayah_labeled = wilayah_df[wilayah_df['cluster_id'].isin(labeled_df['cluster_id'])]
wilayah_not_labeled = wilayah_df[~wilayah_df['cluster_id'].isin(labeled_df['cluster_id'])]
print("labeled data: " + str(wilayah_labeled.shape))
print("non-labeled data: " + str(wilayah_not_labeled.shape))


labeled_merge = pd.merge(wilayah_labeled, labeled_df, on='cluster_id', how='left')
print(labeled_merge.head())

X_wk = labeled_merge.iloc[:, :-2]
y_wk = labeled_merge['label']
print(X_wk.shape)
X_train, X_test, y_train, y_test = train_test_split(X_wk, y_wk, test_size=0.25, random_state=42, stratify=y_wk)
print(X_train.shape)


constraint = "sakoe_chiba" # '' atau 'itakura' 'sakoe_chiba'
slope = 2
radius = 5

def dtw_distance(x, y):
    x_formatted = to_time_series(x)
    y_formatted = to_time_series(y) 
    dtw_score = dtw(x_formatted, y_formatted)
    if(constraint == 'itakura'):
        dtw_score = dtw(x_formatted, y_formatted, global_constraint="itakura", itakura_max_slope=slope)
    elif(constraint == 'sakoe_chiba'):
        dtw_score = dtw(x_formatted, y_formatted, global_constraint="sakoe_chiba", sakoe_chiba_radius=radius)
    return dtw_score
    
    

knn_1 = KNeighborsClassifier(n_neighbors = 5, metric=dtw_distance)
knn_1.fit(X_train, y_train)

y_pred = knn_1.predict(X_test)


def evaluate(y_test, y_pred):
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1 Score: {f1:.4f}")
    
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=np.unique(y_test), 
                yticklabels=np.unique(y_test))
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title('Confusion Matrix')
    plt.show()
evaluate(y_test, y_pred)


scoring = {
    'accuracy': 'accuracy',
    'precision': make_scorer(precision_score, average='weighted'),
    'recall': make_scorer(recall_score, average='weighted'),
    'f1': make_scorer(f1_score, average='weighted')
}


# print(scoring)
skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

stratified_cv_scores = cross_val_score(knn_1, X_wk, y_wk, cv=skf, scoring='accuracy')

print("\nStratified k-fold results:")
for i, score in enumerate(stratified_cv_scores):
    print(f"Fold {i+1}: {score:.4f}")

print(f"\nAverage accuracy (stratified): {np.mean(stratified_cv_scores):.4f}")
print(f"Standard deviation (stratified): {np.std(stratified_cv_scores):.4f}")
#with larger dataset

start_time = time.time()
final_model = KNeighborsClassifier(n_neighbors=5, metric=dtw_score)
final_model.fit(X_wk, y_wk)

pickle.dump(final_model, open(folder_name + 'saved_models/' + f'classification_{curr_kec}.pkl', 'wb'))
predict_all = final_model.predict(wilayah_not_labeled.iloc[:, :-1])
print("--- %s seconds ---" % (time.time() - start_time))


unlabeled_df = wilayah_not_labeled.copy()
unlabeled_df['label'] = predict_all
predicted_df = unlabeled_df.copy()

model_df = wilayah_labeled.copy()
final_df = pd.concat([model_df, predicted_df], axis=0)
final_df.shape


sawah_clusters = final_df[final_df['label'] == 'sawah']
cluster_ids = sawah_clusters['cluster_id'].tolist()


print(cluster_ids)



